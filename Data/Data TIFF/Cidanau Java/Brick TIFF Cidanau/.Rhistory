install.packages("openxlsx")
install.packages("readxl")
install.packages("dplyr")
install.packages("rgdal")
install.packages("raster")
install.packages("e1071")
install.packages("caret")
a <- 92.305
b <- 92.648
c <- 92.411
d <- 92.481
e <- 92.169
sum <- a+b+c+d+e
avg <- sum/5
avg
a <- 76.061
b <- 76.114
c <- 76.085
d <- 76.075
e <- 76.075
sum <- a+b+c+d+e
avg <- sum/5
avg
library(e1701)
install.packages("e1701")
install.packages("e1071")
install.packages("dplyr")
install.packages("caret")
install.packages("Boruta")
library(e1071)
library(caret)
library(Boruta)
library(openxlsx)
library(dplyr)
library(readxl)
install.packages("deSolve")
library(deSolve)
library(deSolve)
seir_model = function (current_timepoint, state_values, parameters)
{
# create state variables (local variables)
S = state_values [1]        # susceptibles
E = state_values [2]        # exposed
I = state_values [3]        # infectious
R = state_values [4]        # recovered
with (
as.list (parameters),     # variable names within parameters can be used
{
# compute derivatives
dS = (-beta * S * I)
dE = (beta * S * I) - (delta * E)
dI = (delta * E) - (gamma * I)
dR = (gamma * I)
# combine results
results = c (dS, dE, dI, dR)
list (results)
}
)
}
contact_rate = 10                     # number of contacts per day
transmission_probability = 0.07       # transmission probability
infectious_period = 5                 # infectious period
latent_period = 2                     # latent period
beta_value = contact_rate * transmission_probability
gamma_value = 1 / infectious_period
delta_value = 1 / latent_period
Ro = beta_value / gamma_value
parameter_list = c (beta = beta_value, gamma = gamma_value, delta = delta_value)
W = 9990        # susceptible hosts (S)
X = 1           # infectious hosts (I)
Y = 0           # recovered hosts (R)
Z = 9           # exposed hosts (E)
N = W + X + Y + Z
initial_values = c (S = W/N, E = X/N, I = Y/N, R = Z/N)
timepoints = seq (0, 50, by=1)
output = lsoda (initial_values, timepoints, seir_model, parameter_list)
output
seir_model()
# susceptible hosts over time
plot (S ~ time, data = output, type='b', ylim = c(0,1), col = 'blue', ylab = 'S, E, I, R', main = 'SEIR epidemic')
# remain on same frame
par (new = TRUE)
# exposed hosts over time
plot (E ~ time, data = output, type='b', ylim = c(0,1), col = 'pink', ylab = '', axes = FALSE)
# remain on same frame
par (new = TRUE)
# infectious hosts over time
plot (I ~ time, data = output, type='b', ylim = c(0,1), col = 'red', ylab = '', axes = FALSE)
# remain on same frame
par (new = TRUE)
# recovered hosts over time
plot (R ~ time, data = output, type='b', ylim = c(0,1), col = 'green', ylab = '', axes = FALSE)
library(deSolve)
seir_model = function (current_timepoint, state_values, parameters)
{
# create state variables (local variables)
S = state_values [1]        # susceptibles
E = state_values [2]        # exposed
I = state_values [3]        # infectious
R = state_values [4]        # recovered
with (
as.list (parameters),     # variable names within parameters can be used
{
# compute derivatives
dS = (-beta * S * I)
dE = (beta * S * I) - (delta * E)
dI = (delta * E) - (gamma * I)
dR = (gamma * I)
# combine results
results = c (dS, dE, dI, dR)
list (results)
}
)
}
contact_rate = 10                     # number of contacts per day
transmission_probability = 0.07       # transmission probability
infectious_period = 5                 # infectious period
latent_period = 2                     # latent period
beta_value = contact_rate * transmission_probability
gamma_value = 1 / infectious_period
delta_value = 1 / latent_period
Ro = beta_value / gamma_value
parameter_list = c (beta = beta_value, gamma = gamma_value, delta = delta_value)
W = 1995        # susceptible hosts (S)
X = 3           # infectious hosts (I)
Y = 0           # recovered hosts (R)
Z = 2           # exposed hosts (E)
N = W + X + Y + Z
initial_values = c (S = W/N, E = X/N, I = Y/N, R = Z/N)
timepoints = seq (0, 50, by=1)
output = lsoda (initial_values, timepoints, seir_model, parameter_list)
plot (S ~ time, data = output, type='b', col = 'blue')
plot (E ~ time, data = output, type='b', col = 'pink')
plot (I ~ time, data = output, type='b', col = 'red')
plot (R ~ time, data = output, type='b', col = 'green')
# susceptible hosts over time
plot (S ~ time, data = output, type='b', ylim = c(0,1), col = 'blue', ylab = 'S, E, I, R', main = 'SEIR Visualization')
# remain on same frame
par (new = TRUE)
# exposed hosts over time
plot (E ~ time, data = output, type='b', ylim = c(0,1), col = 'pink', ylab = '', axes = FALSE)
# remain on same frame
par (new = TRUE)
# infectious hosts over time
plot (I ~ time, data = output, type='b', ylim = c(0,1), col = 'red', ylab = '', axes = FALSE)
# remain on same frame
par (new = TRUE)
# recovered hosts over time
plot (R ~ time, data = output, type='b', ylim = c(0,1), col = 'green', ylab = '', axes = FALSE)
library(deSolve)
seir_model = function (current_timepoint, state_values, parameters)
{
# create state variables (local variables)
S = state_values [1]        # susceptibles
E = state_values [2]        # exposed
I = state_values [3]        # infectious
R = state_values [4]        # recovered
with (
as.list (parameters),     # variable names within parameters can be used
{
# compute derivatives
dS = (-beta * S * I)
dE = (beta * S * I) - (delta * E)
dI = (delta * E) - (gamma * I)
dR = (gamma * I)
# combine results
results = c (dS, dE, dI, dR)
list (results)
}
)
}
contact_rate = 20                     # number of contacts per day
transmission_probability = 0.8       # transmission probability
infectious_period = 5                 # infectious period
latent_period = 8                     # latent period
beta_value = contact_rate * transmission_probability
gamma_value = 1 / infectious_period
delta_value = 1 / latent_period
Ro = beta_value / gamma_value
parameter_list = c (beta = beta_value, gamma = gamma_value, delta = delta_value)
W = 1995        # susceptible hosts (S)
X = 3           # infectious hosts (I)
Y = 0           # recovered hosts (R)
Z = 2           # exposed hosts (E)
N = W + X + Y + Z
initial_values = c (S = W/N, E = X/N, I = Y/N, R = Z/N)
timepoints = seq (0, 50, by=1)
output = lsoda (initial_values, timepoints, seir_model, parameter_list)
plot (S ~ time, data = output, type='b', col = 'blue')
plot (E ~ time, data = output, type='b', col = 'pink')
plot (I ~ time, data = output, type='b', col = 'red')
plot (R ~ time, data = output, type='b', col = 'green')
# susceptible hosts over time
plot (S ~ time, data = output, type='b', ylim = c(0,1), col = 'blue', ylab = 'S, E, I, R', main = 'SEIR Visualization')
# remain on same frame
par (new = TRUE)
# exposed hosts over time
plot (E ~ time, data = output, type='b', ylim = c(0,1), col = 'pink', ylab = '', axes = FALSE)
# remain on same frame
par (new = TRUE)
# infectious hosts over time
plot (I ~ time, data = output, type='b', ylim = c(0,1), col = 'red', ylab = '', axes = FALSE)
# remain on same frame
par (new = TRUE)
# recovered hosts over time
plot (R ~ time, data = output, type='b', ylim = c(0,1), col = 'green', ylab = '', axes = FALSE)
---
title: "Pre-Processing Data for Prediction Model"
author: "Felliks F Tampinongkol, Sahid A Hudjimartsu, Lilik B Prasetyo dan Yudi Setiawan"
date: "Friday / 17 April 2020"
output:
html_document: default
pdf_document: default
word_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Pre-Processing Data LiDAR dan Landsat 8 OLI using Support Vector Regression (SVR)
Data Canopy Cover yang digunakan dapat didownload pada Folder "..."
Berikut merupakan package yang digunakan dalam pre-processing data menggunakan RStudio:
```{r cars}
# install.packages(c("packages_name"))
# library(dbscan, readxl, dplyr, e1071, Boruta, dismo, caret, raster, openxlsx)
rmse <- function(error)
# Fungsi untuk menghitung Nilai root mean squared error (RMSE)
{
sqrt(mean(error^2))
}
```
## Langkah 1 - Set lokasi penyimpanan dan load file excel
```{r}
library(openxlsx)
setwd('C:/Users/Felix/Dropbox/FORESTS2020/00AllData/')
load_data <- read.xlsx("Data Canopy Cover.xlsx")
head(load_data)
summary(load_data)
```
## Langkah 2 - Sleksi dan Balencing Data
Setelah data file berhasil diload selanjutnya data dipilih sesuai dengan kebutuhan. Dalam kasus ini atribut data yang akan digunakan adalah ("Class, frci dan Band_2 sampai Band_7"). Kemudian data yang telah dipilih berdasarkan atribut dilakukan balancing berdasarkan jumlah Class yang memiliki nilai frekuensi terkecil. Tahapan seleksi dan balancing data sebagai berikut:
```{r}
# Tahapan seleksi dan Balancing Data
library(dplyr)
balancing_class <- function(data){
number <- data %>% group_by(Class) %>% summarize(n())
sample <- data %>% group_by(Class) %>% sample_n(min(number$`n()`))
}
data <- load_data[, c("Class", "frci", "Band_2", "Band_3",
"Band_4", "Band_5", "Band_6", "Band_7")]
sample <- balancing_class(data)
sample <- sample[-1] ## Hapus column Class
head(sample)
```
## Langkah 3 - Menghapus Data Pencilan using DBSCAN
Data yang telah diproses dalam Langkah 2, selanjutnya dilakukan pembulatan 3 angka dibelakang koma dan proses membuang outlier atau data pencilan menggunakan algoritma DBSCAN. Proses dapat dilihat seperti dibawah ini:
1. Proses pembulatan 3 Angka dibelakang koma
2. Menentukan nilai epsilon untuk menghapus data pencilan
```{r}
library(dbscan)
lst <- as.data.frame(lapply(sample, function(x) round(x, 3)))
head(lst)
dataSample <- lst
head(dataSample)
# Nilai Epsilon yang digunakan 0.045
kNNdistplot(dataSample, k = 5)
change_data <- 0.045
abline(h = change_data, col = "red", lty = 2)
```
```{r}
res <- dbscan(dataSample, eps = change_data, minPts = 5)
# Ploting sebaran data FRCI terhadap nilai Band Reflektan
pairs(dataSample, col = res$cluster + 1L)
```
Dalam proses ini kita telah memperoleh new data frame ("cleanall") yang kita angap bebas dari outlier atau data pencilan, sehingga data frame inilah yang akan digunakan untuk proses membuat model menggunakan SVR.
```{r}
dataSample$cluster <- res$cluster
cleanall <- dataSample %>% filter(cluster > 0)
# Ploting data sebelum dan sesudah dihapus outlier
par(mfrow=c(1,2))
plot(dataSample$Band_4, dataSample$frci, xlab = 'Band 4 Reflektan',
ylab = 'Nilai FRCI', main = 'Sebelum')
plot(cleanall$Band_4, cleanall$frci, xlab = 'Band 4 Reflektan',
ylab = 'Nilai FRCI', main = 'Sesudah')
```
## Langkah 4 - Boruta dan Support Vector Regression (SVR)
Dalam Langkah ke 4 - pertama yang kita lakukan adalah melihat importance variable menggunakan Boruta algorithm, bertujuan untuk mengetahui variabel-variabel apa saja yang sangat berpengaruh dalam pembuatan model menggunakan Machine Learning. Tapi sebelum itu, kita pastikan bahwa data frame yang akan digunakan untuk membuat model telah sesuai dengan kebutuhan kita.
```{r}
head(cleanall)
svrdata <- cleanall[, -c(8)]
# svrData merupakan data frame baru dari 'cleanall' yang column cluster hasil DBSCAN telah dihilangkan
head(svrdata)
```
```{r}
# Cara untuk menjalankan banyak package sekaligus dalam RStudio
x <- c("Boruta", "caret", "e1071")
lapply(x, FUN = function(X){ do.call("require", list(X)) })
boruta_output <- Boruta(frci ~ ., data=na.omit(svrdata), doTrace=2)
boruta_signif <- names(boruta_output$finalDecision[boruta_output$finalDecision %in% ("Confirmed")])
print(boruta_signif)
plot(boruta_output, cex.axis=.7, las=2, xlab="", main="Variable Importance")
```
<!-- Including Plots -->
<!-- You can also embed plots, for example: -->
<!-- ```{r pressure, echo=FALSE} -->
<!-- plot(pressure) -->
<!-- ``` -->
<!-- Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot. -->
knitr::opts_chunk$set(echo = TRUE)
unlink('D:/00RStudio/R_File_01_cache', recursive = TRUE)
getOption("repos")
CRAN
"https://cran.rstudio.com/ "
attr(,"RStudio")
getOption("repos")
getOption()
getOption(x)
getOption(CRAN.packages())
getOption("repos")
update.packages()
---
title: "Pre-Processing Data for Prediction Model"
install.packages("caTools")
install.packages("rprojroot")
update.packages("knitr")
update.packages("rmarkdown")
update.packages("knitr")
update.packages("rmarkdown")
library(rmarkdown)
library(sf)
library(raster)
library(sf)
library(raster)
raster_brick <- function(rasData){
dt <- brick(rasData)
layers <- dt
for (i in 1:nlayers(layers)){
band <- clip[[i]]
nband <- writeRaster(band, paste("Band_", i, ".tif", sep = ""))
}
return(nband)
}
raster_file <- brick("D:/ix_onepy/Data/Data TIFF/Cidanau Java/subsetcidanau.TIF")
clip <- raster_file
clip
raster_brick(clip)
b2, b3, b4, b5 <- raster_brick(clip)
band_landsat <- raster_brick(clip)
library(sf)
library(raster)
raster_ndvi <- function(nir, red){
ndvi <- (nir - red)/(nir + red)
return(ndvi)
}
raster_savi <- function(nir, red, l){
parm <- 1 + l
savi <- ((nir - red)/(nir + red + l))*parm
return(savi)
}
setwd("D:/ix_onepy/Data/Data TIFF/Cidanau Java/Brick TIFF Cidanau")
ras_nir <- raster("Band_5.tif")
ras_nir
ras_red <- raster("Band_4.tif")
ndvi <- raster_ndvi(ras_nir, ras_red)
writeRaster(ndvi, paste("NDVI_", ".tif", sep = ""))
ndvi
library(sf)
library(raster)
raster_ndvi <- function(nir, red){
ndvi <- (nir - red)/(nir + red)
ndvi <- writeRaster(ndvi, paste("B_NDVI", ".tif", sep = ""))
return(ndvi)
}
raster_savi <- function(nir, red, l){
parm <- 1 + l
savi <- ((nir - red)/(nir + red + l))*parm
savi <- writeRaster(savi, paste("SAVI_", l, ".tif", sep = ""))
return(savi)
}
setwd("D:/ix_onepy/Data/Data TIFF/Cidanau Java/Brick TIFF Cidanau")
ras_nir <- raster("Band_5.tif")
ras_red <- raster("Band_4.tif")
ndvi <- raster_ndvi(ras_nir, ras_red)
savi <- raster_savi(ras_nir, ras_red, 0.5)
ndvi
savi
